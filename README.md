# üß† Diagn√≥stico de C√¢ncer de Mama com IA e Python

Este projeto tem como objetivo aplicar t√©cnicas de Intelig√™ncia Artificial e Engenharia de Dados para diagnosticar tumores de mama como **malignos** ou **benignos**, utilizando a base de dados [Breast Cancer Wisconsin (Diagnostic)](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic). O projeto √© dividido em duas partes: an√°lise e modelagem em Jupyter Notebook, e disponibiliza√ß√£o do modelo via API com Python.

---

## üìÅ Estrutura de Diret√≥rios

```
tech-challenge-3/
‚îú‚îÄ‚îÄ dash_app             # Dashboard para consumir o modelo
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ assets           # Recursos est√°ticos
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ models           # Modelos treinados (.pkl ou .joblib) e arquivos json auxiliares
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ paginas          # Pa«µinas HTML
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt # Depend√™ncias do Dashboard
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile       # Containeriza√ß√£o do Dashboard
‚îú‚îÄ‚îÄ data                 # Dados brutos e tratados
‚îú‚îÄ‚îÄ src/                 # Scripts de pr√©-processamento e treinamento
‚îÇ   ‚îú‚îÄ‚îÄ data/            # Script para importar e salvar o dataset
‚îÇ   ‚îú‚îÄ‚îÄ eda/             # Fun√ß√µes de An√°lise Explorat√≥ria de Dados (EDA)
‚îÇ   ‚îî‚îÄ‚îÄ plots            # Gr√°ficos de avalia√ß√£o de modelos
‚îú‚îÄ‚îÄ notebooks            # Jupyter Notebooks com an√°lise e modelagem
‚îú‚îÄ‚îÄ tests/               # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md            # Documenta√ß√£o principal
```

## üìò Etapas do Projeto

### üî¨ Jupyter Notebook

Notebook: `notebooks/01_exploracao_modelagem.ipynb`

#### 1. Apresenta√ß√£o da Base de Dados
- An√°lise estat√≠stica dos atributos
- Identifica√ß√£o da vari√°vel alvo (`Diagnosis`)
- Limpeza de dados (remo√ß√£o de colunas irrelevantes, tratamento de valores nulos)
- Normaliza√ß√£o ou padroniza√ß√£o dos dados (com justificativa t√©cnica)
- Defini√ß√£o da m√©trica de avalia√ß√£o (ex: F1-score, AUC, acur√°cia)

### 2. Sele√ß√£o de Vari√°veis e Interpreta√ß√£o

**Objetivo.** Reduzir o n√∫mero de vari√°veis **sem perda relevante de desempenho**, priorizando **Recall da classe Maligno** e mantendo interpretabilidade.

**Caminho seguido.**
1. **EDA e qualidade dos dados:** aus√™ncia de valores ausentes; assimetrias/caudas trat√°veis. Para modelos lineares, usamos **imputa√ß√£o mediana + Yeo‚ÄìJohnson**; para √°rvores/boosting, apenas **imputa√ß√£o**.
2. **PCA para interpreta√ß√£o (n√£o para redu√ß√£o):** *scree plot*, dispers√£o PC1√óPC2, **c√≠rculo de correla√ß√µes** e **contribui√ß√µes/cos¬≤** para compreender fam√≠lias de vari√°veis (tamanho/escala, irregularidade/forma, textura/suavidade/simetria, fractalidade).
3. **Ranqueamento supervisionado de vari√°veis:** |correla√ß√£o| com o alvo (ponto-bisserial), **Mutual Information**, **contribui√ß√µes PCA** (PC1/PC2) e **cos¬≤**, compondo um **score**.
4. **Poda por correla√ß√£o (Spearman):** remo√ß√£o gulosa de redund√¢ncias com **|œÅ| ‚â• 0,90**.
5. **Seletores embutidos (SelectFromModel) com CV:** **LR L1**, **LR ElasticNet**, **Random Forest** e **XGBoost**. Calculamos a **frequ√™ncia de sele√ß√£o** por vari√°vel (estabilidade) ao longo dos folds/m√©todos.
6. **Concilia√ß√£o final:** priorizamos vari√°veis mais **est√°veis** (maior *mean_freq*) e reaplicamos a **poda por correla√ß√£o**.

**Pain√©is avaliados em CV (5 folds; modelos: LR_L2, LR_EN, RF, XGB; m√©trica prim√°ria = Recall Maligno):**
- **Full** (todas as vari√°veis);
- **FinalSelected16** (16 vari√°veis);
- **MoreStable12** ‚Üí **12 vari√°veis** (poda estrita):

```text
['worst_concavity', 'worst_area', 'worst_texture', 'worst_smoothness',
'mean_concave_points', 'area_error', 'mean_compactness', 'compactness_error',
'symmetry_error', 'worst_symmetry', 'texture_error', 'concave_points_error']

```

**Resumo dos resultados (m√©trica prim√°ria Recall):**
| Modelo | Recall (MoreStable12 √ó FinalSelected16) | AUC (MoreStable12 √ó FinalSelected16) | AP (MoreStable12 √ó FinalSelected16) |
|--------|------------------------------------------|---------------------------------------|-------------------------------------|
| LR_L2  | **0.9717** = 0.9717 (empate)             | **0.9974** > 0.9970                   | **0.9966** > 0.9962                 |
| LR_EN  | **0.9717** > 0.9670                      | **0.9972** > 0.9968                   | **0.9963** > 0.9959                 |
| RF     | **0.9434** > 0.9340                      | **0.9952** > 0.9942                   | **0.9931** > 0.9924                 |
| XGB    | **0.9763** > 0.9623                      | **0.9962** > 0.9958                   | **0.9946** > 0.9942                 |


**Escolhemos o painel _MoreStable12_ com 12 vari√°veis.**  

Motivos:
1. **Recall** (m√©trica prim√°ria) **‚â•** FinalSelected16 em **todos** os modelos.
2. **AUC/AP** invariavelmente **melhores** tamb√©m em todos os modelos.
3. **Menos vari√°veis** (12 vs 16) ‚áí **menos custo** e **mais usabilidade** (formul√°rio enxuto).
4. Mant√©m **cobertura** das fam√≠lias de sinal (tamanho/escala; irregularidade/forma; textura/suavidade/simetria; variabilidade/error).


#### 3. Avalia√ß√£o de Modelos
- Treinamento e ajuste de hiperpar√¢metros para:
  - Modelo baseado em fun√ß√£o (ex: SVM ou Regress√£o Log√≠stica)
  - Modelo baseado em √°rvore (ex: Random Forest ou XGBoost)
  - Modelo baseado em rede neural *(opcional)*

#### 4. Escolha do Melhor Modelo
- Compara√ß√£o de desempenho entre os modelos
- Justificativa da escolha com base nas m√©tricas

> **Confiabilidade do sinal (Explicabilidade):** A an√°lise com **DALEx** confirmou os sinais aprendidos pelo **LR L2 + MoreStable12** (Permutation Importance, PDP/ICE e Break Down coerentes com coeficientes e PCA). As diverg√™ncias pontuais entre **import√¢ncia por permuta√ß√£o** e **coeficientes** s√£o esperadas devido a colinearidade/redund√¢ncia e refletem impacto **no desempenho global** vs **peso linear**.


### 5. Explicabilidade do Modelo ‚Äî *DALEx*

Notebook: `notebooks/02_explicabilidade_dalex.ipynb`

**Objetivo.** Explicar **global** e **localmente** o modelo final (**LR L2 + MoreStable12**), validando se os sinais aprendidos s√£o clinicamente coerentes e consistentes com as an√°lises anteriores.

**O que entregamos:**

* **Permutation Importance** (baseada em queda de **AP/PR-AUC**): mede impacto pr√°tico de cada vari√°vel no desempenho global ao embaralhar seus valores.
* **PDP/ICE** (parciais e individuais): mostram como a probabilidade prevista varia ao longo do dom√≠nio de cada vari√°vel (efeitos m√©dios e heterogeneidade entre observa√ß√µes).
* **Break Down** (local): decomp√µe a previs√£o de **6 amostras** (p_min, p_max e ~0.20/0.40/0.60/0.80) em contribui√ß√µes pr√≥/contra **Maligno**, partindo do intercepto.

**Principais insights:**

* **Permutation Importance vs. Coeficientes LR**: podem divergir ‚Äî coeficientes medem **peso linear** condicionado aos demais preditores; permuta√ß√£o mede **efeito no desempenho** (captura intera√ß√£o/colinearidade e redund√¢ncias).
* Vari√°veis de "pior caso" (**worst_area**, **worst_texture**, **worst_concavity**) e erros (**area_error**, **concave_points_error**) aparecem **entre as mais influentes**, coerente com os coeficientes e com o PCA interpretativo.
* Nos **Break Down**, casos de baixa probabilidade t√™m **medidas "pior" baixas** (empurram para **Benigno**); casos altos combinam valores "pior" e "erro" elevados (empurram para **Maligno**).

---

### üåê Projeto Web com Python

#### 1. Cria√ß√£o de Dashboard Interativo
- Implementa√ß√£o com **Dash** + **Bootstrap**
- Visualiza√ß√£o de m√©tricas e hiperpar√¢metros do modelo LR_L2 (MoreStable12)
- Explora√ß√£o interativa de vari√°veis e faixas
- Formul√°rio para infer√™ncia em tempo real
- Prepara√ß√£o para execu√ß√£o local e em cont√™iner Docker

##### Funcionalidades:
- **P√°gina In√≠cio**: M√©tricas do modelo, hiperpar√¢metros e informa√ß√µes sobre o painel MoreStable12
- **P√°gina Formul√°rio**: Inputs para as 12 vari√°veis com valida√ß√£o e bot√£o de predi√ß√£o
- **P√°gina Gr√°ficos**: Import√¢ncia das vari√°veis e histogramas explorat√≥rios

#### 2. Funcionalidades Adicionais *(opcionais)*
- Autentica√ß√£o via JWT
- Integra√ß√£o com Gateway/API Manager

---

## üõ† Tecnologias Utilizadas

| Categoria                      | Ferramentas                                                                                    |
|--------------------------------|-------------------------------------------------------------------------------------------------|
| Linguagem                      | Python 3.10+                                                                                   |
| An√°lise de Dados               | Pandas, NumPy, SciPy, Matplotlib e Seaborn                                                     |
| Machine Learning               | Scikit-learn, XGBoost                                                                          |
| Sele√ß√£o de Vari√°veis & Interpreta√ß√£o | SelectFromModel (LR L1/ElasticNet, RF, XGB), Mutual Information, Correla√ß√£o (Spearman), **PCA para interpreta√ß√£o** |
| Explicabilidade                | DALEx (Permutation Importance, PDP/ICE, Break Down)                                            |
| Dashboard                      | Dash, Dash-bootstrap-components, Plotly, Flask e Gunicorn                                      |
| Deploy                         | Docker *(opcional)*                                                                            |


---

## üì¶ Como Executar

### 1. Clonar o reposit√≥rio
```bash
git clone https://github.com/djflucena/tech-challenge-3.git
cd tech-challenge-3
```
